{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79738a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkorayem/anaconda3/envs/ITI/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"eriktks/conll2003\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5453e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b7ff4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: \"O\",       \n",
    "    1: \"B-PER\",   \n",
    "    2: \"I-PER\",   \n",
    "    3: \"B-ORG\",  \n",
    "    4: \"I-ORG\",   \n",
    "    5: \"B-LOC\",  \n",
    "    6: \"I-LOC\",   \n",
    "    7: \"B-MISC\",  \n",
    "    8: \"I-MISC\", \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f99c7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'tokens': ['EU',\n",
       "  'rejects',\n",
       "  'German',\n",
       "  'call',\n",
       "  'to',\n",
       "  'boycott',\n",
       "  'British',\n",
       "  'lamb',\n",
       "  '.'],\n",
       " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
       " 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
       " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4f8bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training.iob_utils import biluo_tags_to_offsets\n",
    "from spacy.training.iob_utils import iob_to_biluo\n",
    "def convert_entry(entry, label_map, nlp):\n",
    "    tokens = entry['tokens']\n",
    "    ner_tags = [label_map.get(tag, 'O') for tag in entry['ner_tags']]\n",
    "    text = \" \".join(tokens)\n",
    "    doc = nlp(text)\n",
    "    biluo_tags = iob_to_biluo(ner_tags)\n",
    "    spans = biluo_tags_to_offsets(doc, biluo_tags)\n",
    "    entities = [doc.char_span(start, end, label=label) for start, end, label in spans if doc.char_span(start, end, label=label)]\n",
    "    doc.ents = entities\n",
    "    return doc\n",
    "\n",
    "# Main conversion\n",
    "def convert_dataset(dataset, label_map, output_path):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    db = DocBin()\n",
    "    for entry in dataset:\n",
    "        doc = convert_entry(entry, label_map, nlp)\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132ee29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee6d099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EU rejects German call to boycott British lamb .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "doc = convert_entry(sample, label_map, nlp)\n",
    "doc.ents\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df3ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dataset(data['train'], label_map, \"train.spacy\")\n",
    "convert_dataset(data['test'], label_map, \"test.spacy\")\n",
    "convert_dataset(data['validation'], label_map, \"validation.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1e5e8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     44.28    0.00    0.00    0.00    0.00\n",
      "  0     200        613.24   3547.70   35.52   43.82   29.86    0.36\n",
      "  0     400        243.50   2935.96   52.03   54.26   49.98    0.52\n",
      "  0     600        286.67   2865.47   63.14   64.85   61.51    0.63\n",
      "  0     800        374.02   2995.49   67.54   69.03   66.12    0.68\n",
      "  0    1000        550.72   3641.20   69.48   71.55   67.54    0.69\n",
      "  1    1200        642.22   3773.55   72.97   74.70   71.32    0.73\n",
      "  1    1400        776.95   3766.72   71.84   73.79   69.99    0.72\n",
      "  1    1600        984.89   4565.72   74.45   76.56   72.45    0.74\n",
      "  2    1800       1337.73   4864.46   74.95   77.45   72.60    0.75\n",
      "  2    2000       1471.45   5340.40   75.66   78.88   72.70    0.76\n",
      "  3    2200       1839.61   5214.81   75.87   79.40   72.64    0.76\n",
      "  4    2400       2173.77   5772.27   75.54   78.33   72.94    0.76\n",
      "  5    2600       2476.18   5305.34   75.17   78.40   72.20    0.75\n",
      "  6    2800       2434.28   4477.26   75.25   77.26   73.34    0.75\n",
      "  7    3000       2564.00   4209.52   75.59   77.30   73.96    0.76\n",
      "  8    3200       2445.58   3563.29   76.40   77.85   75.01    0.76\n",
      "  9    3400       2375.69   3277.94   76.36   77.43   75.33    0.76\n",
      "  9    3600       2473.58   3036.52   76.99   78.56   75.48    0.77\n",
      " 10    3800       2464.94   2734.83   75.70   77.16   74.30    0.76\n",
      " 11    4000       2208.35   2479.51   76.59   77.23   75.97    0.77\n",
      " 12    4200       2101.47   2269.32   76.39   77.81   75.03    0.76\n",
      " 13    4400       2374.75   2302.25   76.01   77.10   74.96    0.76\n",
      " 14    4600       2243.32   2107.66   75.78   76.41   75.16    0.76\n",
      " 15    4800       2250.97   2041.07   76.20   78.08   74.40    0.76\n",
      " 16    5000       2093.60   1875.70   76.23   79.27   73.41    0.76\n",
      " 17    5200       2106.72   1755.30   76.15   76.53   75.78    0.76\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./validation.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51f8929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
      "\u001b[1m\n",
      "================================== Results ==================================\u001b[0m\n",
      "\n",
      "TOK     100.00\n",
      "NER P   73.61 \n",
      "NER R   70.41 \n",
      "NER F   71.98 \n",
      "SPEED   16058 \n",
      "\n",
      "\u001b[1m\n",
      "=============================== NER (per type) ===============================\u001b[0m\n",
      "\n",
      "           P       R       F\n",
      "LOC    75.06   77.04   76.04\n",
      "PER    74.24   70.75   72.45\n",
      "ORG    72.48   67.07   69.67\n",
      "MISC   70.80   61.82   66.01\n",
      "\n",
      "\u001b[38;5;2m✔ Saved results to metrics.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy evaluate output/model-best test.spacy --output metrics.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "715b7978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7360725523 0.7041430595 0.7197538684\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"metrics.json\", \"r\") as f:\n",
    "    metrics = json.load(f)\n",
    "print(metrics[\"ents_p\"], metrics[\"ents_r\"], metrics[\"ents_f\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70d31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
